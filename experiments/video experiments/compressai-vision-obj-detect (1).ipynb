{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b3199b9-5fdb-4b71-a988-ec9ccda935d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, argparse, math, itertools\n",
    "import torch, torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from compressai.zoo import bmshj2018_factorized, ssf2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3662a7b9-f2e4-48be-a597-aa70e223a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mot17_root = \"BoostTrack/data/MOT17/test\"\n",
    "sequence = \"MOT17-01-DPM\"\n",
    "img_folder = os.path.join(mot17_root, sequence, 'img1')\n",
    "output_folder = os.path.join('BoostTrack/data/MOT17-compressed', sequence)\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f24d69cf-1c4d-47d0-b657-fc710d2d4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_multiple(x, m):\n",
    "    \"\"\"\n",
    "    Reflect-pad so (H, W) is a multiple of m.\n",
    "    SSF / other video codecs need m = 128; most image codecs work with 64.\n",
    "    \"\"\"\n",
    "    B, C, H, W = x.shape\n",
    "    Hp, Wp = (m - H % m) % m, (m - W % m) % m\n",
    "    return F.pad(x, (0, Wp, 0, Hp), mode=\"reflect\"), (H, W)\n",
    "\n",
    "def bits_in(strings):\n",
    "    return sum(len(s) * 8 for s in flatten(strings))\n",
    "\n",
    "def flatten(l):\n",
    "    for el in l:\n",
    "        if isinstance(el, (list, tuple)):\n",
    "            yield from flatten(el)\n",
    "        else:\n",
    "            yield el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0667778-dfd8-4e21-bd3f-36c82ee2bae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://compressai.s3.amazonaws.com/models/v1/ssf2020-mse-6-59dfb6f9.pth.tar\" to /home/jovyan/.cache/torch/hub/checkpoints/ssf2020-mse-6-59dfb6f9.pth.tar\n",
      "100%|██████████| 133M/133M [00:24<00:00, 5.81MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ScaleSpaceFlow(\n",
       "  (img_encoder): Encoder(\n",
       "    (0): Conv2d(3, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(128, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  )\n",
       "  (img_decoder): Decoder(\n",
       "    (0): ConvTranspose2d(192, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): ConvTranspose2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): ConvTranspose2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(128, 3, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "  )\n",
       "  (img_hyperprior): Hyperprior(\n",
       "    (entropy_bottleneck): EntropyBottleneck(\n",
       "      (likelihood_lower_bound): LowerBound()\n",
       "      (matrices): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (1): Parameter containing: [torch.float32 of size 192x3x3 (cuda:0)]\n",
       "          (2): Parameter containing: [torch.float32 of size 192x3x3 (cuda:0)]\n",
       "          (3): Parameter containing: [torch.float32 of size 192x3x3 (cuda:0)]\n",
       "          (4): Parameter containing: [torch.float32 of size 192x1x3 (cuda:0)]\n",
       "      )\n",
       "      (biases): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (1): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (2): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (3): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (4): Parameter containing: [torch.float32 of size 192x1x1 (cuda:0)]\n",
       "      )\n",
       "      (factors): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (1): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (2): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (3): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "      )\n",
       "    )\n",
       "    (hyper_encoder): HyperEncoder(\n",
       "      (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    )\n",
       "    (hyper_decoder_mean): HyperDecoder(\n",
       "      (0): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    )\n",
       "    (hyper_decoder_scale): HyperDecoderWithQReLU(\n",
       "      (deconv1): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "      (deconv2): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "      (deconv3): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    )\n",
       "    (gaussian_conditional): GaussianConditional(\n",
       "      (likelihood_lower_bound): LowerBound()\n",
       "      (lower_bound_scale): LowerBound()\n",
       "    )\n",
       "  )\n",
       "  (res_encoder): Encoder(\n",
       "    (0): Conv2d(3, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(128, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  )\n",
       "  (res_decoder): Decoder(\n",
       "    (0): ConvTranspose2d(384, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): ConvTranspose2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): ConvTranspose2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(128, 3, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "  )\n",
       "  (res_hyperprior): Hyperprior(\n",
       "    (entropy_bottleneck): EntropyBottleneck(\n",
       "      (likelihood_lower_bound): LowerBound()\n",
       "      (matrices): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (1): Parameter containing: [torch.float32 of size 192x3x3 (cuda:0)]\n",
       "          (2): Parameter containing: [torch.float32 of size 192x3x3 (cuda:0)]\n",
       "          (3): Parameter containing: [torch.float32 of size 192x3x3 (cuda:0)]\n",
       "          (4): Parameter containing: [torch.float32 of size 192x1x3 (cuda:0)]\n",
       "      )\n",
       "      (biases): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (1): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (2): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (3): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (4): Parameter containing: [torch.float32 of size 192x1x1 (cuda:0)]\n",
       "      )\n",
       "      (factors): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (1): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (2): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (3): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "      )\n",
       "    )\n",
       "    (hyper_encoder): HyperEncoder(\n",
       "      (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    )\n",
       "    (hyper_decoder_mean): HyperDecoder(\n",
       "      (0): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    )\n",
       "    (hyper_decoder_scale): HyperDecoderWithQReLU(\n",
       "      (deconv1): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "      (deconv2): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "      (deconv3): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    )\n",
       "    (gaussian_conditional): GaussianConditional(\n",
       "      (likelihood_lower_bound): LowerBound()\n",
       "      (lower_bound_scale): LowerBound()\n",
       "    )\n",
       "  )\n",
       "  (motion_encoder): Encoder(\n",
       "    (0): Conv2d(6, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(128, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  )\n",
       "  (motion_decoder): Decoder(\n",
       "    (0): ConvTranspose2d(192, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): ConvTranspose2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): ConvTranspose2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(128, 3, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "  )\n",
       "  (motion_hyperprior): Hyperprior(\n",
       "    (entropy_bottleneck): EntropyBottleneck(\n",
       "      (likelihood_lower_bound): LowerBound()\n",
       "      (matrices): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (1): Parameter containing: [torch.float32 of size 192x3x3 (cuda:0)]\n",
       "          (2): Parameter containing: [torch.float32 of size 192x3x3 (cuda:0)]\n",
       "          (3): Parameter containing: [torch.float32 of size 192x3x3 (cuda:0)]\n",
       "          (4): Parameter containing: [torch.float32 of size 192x1x3 (cuda:0)]\n",
       "      )\n",
       "      (biases): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (1): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (2): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (3): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (4): Parameter containing: [torch.float32 of size 192x1x1 (cuda:0)]\n",
       "      )\n",
       "      (factors): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (1): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (2): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "          (3): Parameter containing: [torch.float32 of size 192x3x1 (cuda:0)]\n",
       "      )\n",
       "    )\n",
       "    (hyper_encoder): HyperEncoder(\n",
       "      (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    )\n",
       "    (hyper_decoder_mean): HyperDecoder(\n",
       "      (0): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    )\n",
       "    (hyper_decoder_scale): HyperDecoderWithQReLU(\n",
       "      (deconv1): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "      (deconv2): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "      (deconv3): ConvTranspose2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    )\n",
       "    (gaussian_conditional): GaussianConditional(\n",
       "      (likelihood_lower_bound): LowerBound()\n",
       "      (lower_bound_scale): LowerBound()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "quality = 6\n",
    "model = ssf2020(quality=quality, metric='mse', pretrained=True).to(device) \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8087dc6-298f-420c-88c4-5c93d9ef2f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_codec = True\n",
    "PAD_M = 128\n",
    "to_tensor = transforms.ToTensor()\n",
    "frames = sorted(glob.glob(os.path.join(img_folder, \"*.jpg\"))\n",
    "                + glob.glob(os.path.join(img_folder, \"*.png\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df5759ff-9442-4c75-a466-3ffe8b2e42f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading frames: 100%|██████████| 450/450 [00:23<00:00, 19.22it/s]\n"
     ]
    }
   ],
   "source": [
    "total_bits, orig_hws = 0, []\n",
    "strings_list, shapes_list = [], []\n",
    "\n",
    "clip = []\n",
    "for fp in tqdm(frame_paths, desc=\"Loading frames\"):\n",
    "    img = Image.open(fp).convert(\"RGB\")\n",
    "    x   = to_tensor(img).unsqueeze(0).to(device)\n",
    "    x, hw = pad_to_multiple(x, PAD_M)\n",
    "    clip.append(x)\n",
    "    orig_hws.append(hw)\n",
    "\n",
    "with torch.no_grad():\n",
    "    strings_list, shapes_list = model.compress(clip)\n",
    "\n",
    "for i, (s, sh, hw) in enumerate(zip(strings_list, shapes_list, orig_hws)):\n",
    "    torch.save({\"strings\": s, \"shape\": sh, \"orig_hw\": hw},\n",
    "                os.path.join(output_folder, f\"{i:06d}.pth\"))\n",
    "    total_bits += bits_in(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef959180-e1ba-4572-b765-0394a9d4be7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed → BoostTrack/data/MOT17-compressed/MOT17-01-DPM\n",
      "Total size : 125.1 kB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Compressed → {output_folder}\")\n",
    "print(f\"Total size : {total_bits/8/1024:.1f} kB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4e2a7a0e-d22a-4e49-92e2-99e848c6bae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring:   0%|          | 0/450 [00:00<?, ?it/s]/tmp/ipykernel_292764/3201988151.py:18: UserWarning: Using a target size (torch.Size([3, 1080, 1920])) that is different to the input size (torch.Size([1, 3, 1080, 1920])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  mse   = F.mse_loss(x_hat, x_ref)\n",
      "Scoring: 100%|██████████| 450/450 [00:24<00:00, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sequence average →  0.0011 bpp   |   40.12 dB PSNR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "psnr_sum = 0.0\n",
    "n_pixels = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    if video_codec:\n",
    "        recon_clip = model.decompress(strings_list, shapes_list)\n",
    "\n",
    "    for i, fp in enumerate(tqdm(frame_paths, desc=\"Scoring\")):\n",
    "        if video_codec:\n",
    "            x_hat = recon_clip[i]\n",
    "        else:\n",
    "            x_hat = model.decompress([strings_list[i]], [shapes_list[i]])[0]\n",
    "\n",
    "        H, W  = orig_hws[i]\n",
    "        x_hat = x_hat[..., :H, :W].clamp_(0, 1)\n",
    "\n",
    "        x_ref = to_tensor(Image.open(fp).convert(\"RGB\")).to(device)\n",
    "        mse   = F.mse_loss(x_hat, x_ref)\n",
    "        psnr  = -10 * torch.log10(mse)\n",
    "\n",
    "        psnr_sum += psnr.item()\n",
    "        n_pixels += H * W\n",
    "\n",
    "avg_psnr = psnr_sum / len(frame_paths)\n",
    "bpp      = total_bits / n_pixels\n",
    "\n",
    "print(f\"\\nSequence average →  {bpp:.4f} bpp   |   {avg_psnr:.2f} dB PSNR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53f240-f4e1-485a-84fa-1d111d6ed2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84882b63-113c-4921-9d38-285bea30c324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73952b3f-0ac1-4dd6-92a4-8068d59de8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, math, itertools, shutil, gc\n",
    "import torch, torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as _np\n",
    "if not hasattr(_np, \"object\"):\n",
    "    _np.object = object\n",
    "    \n",
    "from torchvision import transforms\n",
    "from compressai.zoo import bmshj2018_factorized, ssf2020 \n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "734023fa-09ba-457e-88be-f7bc525e5d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "mot17_root = \"BoostTrack/data/MOT17_original/test\"     \n",
    "out_root   = \"BoostTrack/data/MOT17/test\"\n",
    "\n",
    "codec_name = \"ssf2020\"        \n",
    "quality    = 6\n",
    "\n",
    "# Set GOP_SIZE=None to encode an entire sequence in one call.\n",
    "GOP_SIZE   = 12 if codec_name.startswith(\"ssf\") else None\n",
    "\n",
    "device     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7347044-f2c6-4c74-bb29-4b8632ad938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_multiple(x, m):\n",
    "    \"\"\"Reflect-pad so (H, W) is divisible by *m*.\"\"\"\n",
    "    B, C, H, W = x.shape\n",
    "    Hp, Wp = (m - H % m) % m, (m - W % m) % m\n",
    "    return F.pad(x, (0, Wp, 0, Hp), mode=\"reflect\"), (H, W)\n",
    "\n",
    "def flatten(nested):\n",
    "    for el in nested:\n",
    "        if isinstance(el, (list, tuple)):\n",
    "            yield from flatten(el)\n",
    "        else:\n",
    "            yield el\n",
    "\n",
    "def bits_in(strings):\n",
    "    return sum(len(s) * 8 for s in flatten(strings))\n",
    "\n",
    "to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02786c36-a927-4c3d-9e86-da54715b0d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ssf2020-Q6  (video=True)\n"
     ]
    }
   ],
   "source": [
    "if codec_name == \"bmshj2018_factorized\":\n",
    "    model      = bmshj2018_factorized(quality=quality, pretrained=True).eval().to(device)\n",
    "    video_code = False\n",
    "    PAD_M      = 64\n",
    "elif codec_name == \"ssf2020\":\n",
    "    model      = ssf2020(quality=quality, pretrained=True).eval().to(device)\n",
    "    video_code = True\n",
    "    PAD_M      = 128         # SSF ↓16, hyper-prior ↑8 → needs /128\n",
    "else:\n",
    "    raise ValueError(f\"Unknown codec {codec_name}\")\n",
    "\n",
    "print(f\"Loaded {codec_name}-Q{quality}  (video={video_code})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "329286bd-cf2f-4a46-b31d-6b684cba3ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 sequences:\n",
      " • MOT17-01-DPM\n",
      " • MOT17-01-FRCNN\n",
      " • MOT17-01-SDP\n",
      " • MOT17-03-DPM\n",
      " • MOT17-03-FRCNN\n",
      " • MOT17-03-SDP\n",
      " • MOT17-06-DPM\n",
      " • MOT17-06-FRCNN\n",
      " • MOT17-06-SDP\n",
      " • MOT17-07-DPM\n",
      " • MOT17-07-FRCNN\n",
      " • MOT17-07-SDP\n",
      " • MOT17-08-DPM\n",
      " • MOT17-08-FRCNN\n",
      " • MOT17-08-SDP\n",
      " • MOT17-12-DPM\n",
      " • MOT17-12-FRCNN\n",
      " • MOT17-12-SDP\n",
      " • MOT17-14-DPM\n",
      " • MOT17-14-FRCNN\n",
      " • MOT17-14-SDP\n"
     ]
    }
   ],
   "source": [
    "sequences = [d for d in os.listdir(mot17_root)\n",
    "             if os.path.isdir(os.path.join(mot17_root, d, \"img1\"))]\n",
    "sequences.sort()\n",
    "print(\"Found\", len(sequences), \"sequences:\")\n",
    "for s in sequences: print(\" •\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49266158-2ab5-4c9b-ab6b-abe16fc3c5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MOT17-01-DPM ===\n",
      "Frames: 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_459990/2599402374.py:51: UserWarning: Using a target size (torch.Size([3, 1080, 1920])) that is different to the input size (torch.Size([1, 3, 1080, 1920])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  mse   = F.mse_loss(x_hat, x_ref)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ 0.0384 bpp   |   40.24 dB PSNR\n",
      "\n",
      "=== MOT17-01-FRCNN ===\n",
      "Frames: 450\n",
      "→ 0.0384 bpp   |   40.24 dB PSNR\n",
      "\n",
      "=== MOT17-01-SDP ===\n",
      "Frames: 450\n",
      "→ 0.0384 bpp   |   40.24 dB PSNR\n",
      "\n",
      "=== MOT17-03-DPM ===\n",
      "Frames: 1500\n",
      "→ 0.0288 bpp   |   41.14 dB PSNR\n",
      "\n",
      "=== MOT17-03-FRCNN ===\n",
      "Frames: 1500\n",
      "→ 0.0288 bpp   |   41.14 dB PSNR\n",
      "\n",
      "=== MOT17-03-SDP ===\n",
      "Frames: 1500\n",
      "→ 0.0288 bpp   |   41.14 dB PSNR\n",
      "\n",
      "=== MOT17-06-DPM ===\n",
      "Frames: 1194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_459990/2599402374.py:51: UserWarning: Using a target size (torch.Size([3, 480, 640])) that is different to the input size (torch.Size([1, 3, 480, 640])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  mse   = F.mse_loss(x_hat, x_ref)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ 0.0341 bpp   |   35.63 dB PSNR\n",
      "\n",
      "=== MOT17-06-FRCNN ===\n",
      "Frames: 1194\n",
      "→ 0.0341 bpp   |   36.94 dB PSNR\n",
      "\n",
      "=== MOT17-06-SDP ===\n",
      "Frames: 1194\n",
      "→ 0.0341 bpp   |   35.35 dB PSNR\n",
      "\n",
      "=== MOT17-07-DPM ===\n",
      "Frames: 500\n"
     ]
    }
   ],
   "source": [
    "summary = []          # will collect (seq, frames, bpp, psnr)\n",
    "for seq in sequences:\n",
    "    print(f\"\\n=== {seq} ===\")\n",
    "    img_dir = os.path.join(mot17_root, seq, \"img1\")\n",
    "    out_dir = os.path.join(out_root,   seq)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    out_dir_img1 = os.path.join(out_root, seq, \"img1\")\n",
    "    os.makedirs(out_dir_img1, exist_ok=True)\n",
    "\n",
    "    det_src = os.path.join(mot17_root, seq, \"det\")\n",
    "    det_dst = os.path.join(out_root,   seq, \"det\")\n",
    "    if not os.path.exists(det_dst):\n",
    "        shutil.copytree(det_src, det_dst)\n",
    "    shutil.copy(os.path.join(mot17_root, seq, \"seqinfo.ini\"),\n",
    "                os.path.join(out_root,   seq, \"seqinfo.ini\"))\n",
    "\n",
    "    frame_paths = sorted(glob.glob(os.path.join(img_dir, \"*.jpg\")) +\n",
    "                         glob.glob(os.path.join(img_dir, \"*.png\")))\n",
    "    n_frames = len(frame_paths)\n",
    "    print(\"Frames:\", n_frames)\n",
    "\n",
    "    total_bits, psnr_sum, n_pixels = 0, 0.0, 0\n",
    "\n",
    "    if video_code:\n",
    "        # ── process in chunks (=GOPs) to control memory\n",
    "        gop = n_frames if GOP_SIZE is None else GOP_SIZE\n",
    "        for g in range(0, n_frames, gop):\n",
    "            end = min(g + gop, n_frames)\n",
    "            clip, orig_hws = [], []\n",
    "            for fp in frame_paths[g:end]:\n",
    "                img = Image.open(fp).convert(\"RGB\")\n",
    "                x, hw = pad_to_multiple(to_tensor(img).unsqueeze(0).to(device), PAD_M)\n",
    "                clip.append(x); orig_hws.append(hw)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                strings, shapes = model.compress(clip)\n",
    "\n",
    "            # save + metrics\n",
    "            recon = model.decompress(strings, shapes)\n",
    "            for i, (st, sh, hw, x_hat, fp) in enumerate(zip(\n",
    "                    strings, shapes, orig_hws, recon, frame_paths[g:end])):\n",
    "                idx = g + i\n",
    "                # torch.save({\"strings\": st, \"shape\": sh, \"orig_hw\": hw},\n",
    "                #            os.path.join(out_dir, f\"{idx:06d}.pth\"))\n",
    "                total_bits += bits_in(st)\n",
    "\n",
    "                H, W = hw\n",
    "                x_hat = x_hat[..., :H, :W].clamp_(0, 1)\n",
    "                x_ref = to_tensor(Image.open(fp).convert(\"RGB\")).to(device)\n",
    "                mse   = F.mse_loss(x_hat, x_ref)\n",
    "                psnr  = -10 * torch.log10(mse)\n",
    "                psnr_sum += psnr.item()\n",
    "                n_pixels += H * W\n",
    "\n",
    "                rgb8 = (x_hat.squeeze(0).permute(1, 2, 0).clamp_(0, 1).cpu().detach().numpy() * 255).round().astype('uint8')\n",
    "\n",
    "                # write JPEG with MOT naming\n",
    "                cv2.imwrite(os.path.join(out_dir_img1, f\"{idx+1:06d}.jpg\"),\n",
    "                            cv2.cvtColor(rgb8, cv2.COLOR_RGB2BGR),\n",
    "                            [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
    "\n",
    "            # free GPU mem each GOP\n",
    "            del clip, recon, strings, shapes\n",
    "            torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "    else:  # ── image codec\n",
    "        for idx, fp in enumerate(tqdm(frame_paths, desc=\"Compressing\")):\n",
    "            img = Image.open(fp).convert(\"RGB\")\n",
    "            x, hw = pad_to_multiple(to_tensor(img).unsqueeze(0).to(device), PAD_M)\n",
    "            with torch.no_grad():\n",
    "                out = model.compress(x)\n",
    "                x_hat = model.decompress(out[\"strings\"], out[\"shape\"])[0]\n",
    "\n",
    "            torch.save({\"strings\": out[\"strings\"], \"shape\": out[\"shape\"], \"orig_hw\": hw},\n",
    "                       os.path.join(out_dir, f\"{idx:06d}.pth\"))\n",
    "            total_bits += bits_in(out[\"strings\"])\n",
    "\n",
    "            H, W  = hw\n",
    "            x_hat = x_hat[..., :H, :W].clamp_(0, 1)\n",
    "            mse   = F.mse_loss(x_hat, to_tensor(img).to(device))\n",
    "            psnr  = -10 * torch.log10(mse)\n",
    "            psnr_sum += psnr.item()\n",
    "            n_pixels += H * W\n",
    "\n",
    "    bpp  = total_bits / n_pixels\n",
    "    psnr = psnr_sum / n_frames\n",
    "    summary.append((seq, n_frames, bpp, psnr))\n",
    "    print(f\"→ {bpp:.4f} bpp   |   {psnr:.2f} dB PSNR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8752732-1af3-434b-b6a6-02baca9301d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===========  SUMMARY  ===========\")\n",
    "print(f\"{'Sequence':20}  Frames   BPP     PSNR\")\n",
    "for seq, n, bpp, psnr in summary:\n",
    "    print(f\"{seq:20}  {n:6d}   {bpp:5.4f}   {psnr:6.2f}\")\n",
    "overall_bpp  = sum(bpp*n for (_,n,bpp,_) in summary) / sum(n for (_,n,_,_) in summary)\n",
    "overall_psnr = sum(psnr*n for (_,n,_,psnr) in summary) / sum(n for (_,n,_,_) in summary)\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"{'Overall':20}          {overall_bpp:5.4f}   {overall_psnr:6.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b23a2-44ca-406e-86e1-b9826a3379c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mot17_root = \"BoostTrack/data/MOT17_original/train\"     \n",
    "out_root   = \"BoostTrack/data/MOT17/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ff6e1-dc3c-4563-b80d-25ece9499997",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [d for d in os.listdir(mot17_root)\n",
    "             if os.path.isdir(os.path.join(mot17_root, d, \"img1\"))]\n",
    "sequences.sort()\n",
    "print(\"Found\", len(sequences), \"sequences:\")\n",
    "for s in sequences: print(\" •\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb87e34-4e8d-473f-bcf1-407248ea8217",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = []          # will collect (seq, frames, bpp, psnr)\n",
    "for seq in sequences:\n",
    "    print(f\"\\n=== {seq} ===\")\n",
    "    img_dir = os.path.join(mot17_root, seq, \"img1\")\n",
    "    out_dir = os.path.join(out_root,   seq)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    out_dir_img1 = os.path.join(out_root, seq, \"img1\")\n",
    "    os.makedirs(out_dir_img1, exist_ok=True)\n",
    "\n",
    "    det_src = os.path.join(mot17_root, seq, \"det\")\n",
    "    det_dst = os.path.join(out_root,   seq, \"det\")\n",
    "    if not os.path.exists(det_dst):\n",
    "        shutil.copytree(det_src, det_dst)\n",
    "    shutil.copy(os.path.join(mot17_root, seq, \"seqinfo.ini\"),\n",
    "                os.path.join(out_root,   seq, \"seqinfo.ini\"))\n",
    "\n",
    "    frame_paths = sorted(glob.glob(os.path.join(img_dir, \"*.jpg\")) +\n",
    "                         glob.glob(os.path.join(img_dir, \"*.png\")))\n",
    "    n_frames = len(frame_paths)\n",
    "    print(\"Frames:\", n_frames)\n",
    "\n",
    "    total_bits, psnr_sum, n_pixels = 0, 0.0, 0\n",
    "\n",
    "    if video_code:\n",
    "        # ── process in chunks (=GOPs) to control memory\n",
    "        gop = n_frames if GOP_SIZE is None else GOP_SIZE\n",
    "        for g in range(0, n_frames, gop):\n",
    "            end = min(g + gop, n_frames)\n",
    "            clip, orig_hws = [], []\n",
    "            for fp in frame_paths[g:end]:\n",
    "                img = Image.open(fp).convert(\"RGB\")\n",
    "                x, hw = pad_to_multiple(to_tensor(img).unsqueeze(0).to(device), PAD_M)\n",
    "                clip.append(x); orig_hws.append(hw)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                strings, shapes = model.compress(clip)\n",
    "\n",
    "            # save + metrics\n",
    "            recon = model.decompress(strings, shapes)\n",
    "            for i, (st, sh, hw, x_hat, fp) in enumerate(zip(\n",
    "                    strings, shapes, orig_hws, recon, frame_paths[g:end])):\n",
    "                idx = g + i\n",
    "                # torch.save({\"strings\": st, \"shape\": sh, \"orig_hw\": hw},\n",
    "                #            os.path.join(out_dir, f\"{idx:06d}.pth\"))\n",
    "                total_bits += bits_in(st)\n",
    "\n",
    "                H, W = hw\n",
    "                x_hat = x_hat[..., :H, :W].clamp_(0, 1)\n",
    "                x_ref = to_tensor(Image.open(fp).convert(\"RGB\")).to(device)\n",
    "                mse   = F.mse_loss(x_hat, x_ref)\n",
    "                psnr  = -10 * torch.log10(mse)\n",
    "                psnr_sum += psnr.item()\n",
    "                n_pixels += H * W\n",
    "\n",
    "                rgb8 = (x_hat.squeeze(0).permute(1, 2, 0).clamp_(0, 1).cpu().detach().numpy() * 255).round().astype('uint8')\n",
    "\n",
    "                # write JPEG with MOT naming\n",
    "                cv2.imwrite(os.path.join(out_dir_img1, f\"{idx+1:06d}.jpg\"),\n",
    "                            cv2.cvtColor(rgb8, cv2.COLOR_RGB2BGR),\n",
    "                            [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
    "\n",
    "            # free GPU mem each GOP\n",
    "            del clip, recon, strings, shapes\n",
    "            torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "    else:  # ── image codec\n",
    "        for idx, fp in enumerate(tqdm(frame_paths, desc=\"Compressing\")):\n",
    "            img = Image.open(fp).convert(\"RGB\")\n",
    "            x, hw = pad_to_multiple(to_tensor(img).unsqueeze(0).to(device), PAD_M)\n",
    "            with torch.no_grad():\n",
    "                out = model.compress(x)\n",
    "                x_hat = model.decompress(out[\"strings\"], out[\"shape\"])[0]\n",
    "\n",
    "            torch.save({\"strings\": out[\"strings\"], \"shape\": out[\"shape\"], \"orig_hw\": hw},\n",
    "                       os.path.join(out_dir, f\"{idx:06d}.pth\"))\n",
    "            total_bits += bits_in(out[\"strings\"])\n",
    "\n",
    "            H, W  = hw\n",
    "            x_hat = x_hat[..., :H, :W].clamp_(0, 1)\n",
    "            mse   = F.mse_loss(x_hat, to_tensor(img).to(device))\n",
    "            psnr  = -10 * torch.log10(mse)\n",
    "            psnr_sum += psnr.item()\n",
    "            n_pixels += H * W\n",
    "\n",
    "    bpp  = total_bits / n_pixels\n",
    "    psnr = psnr_sum / n_frames\n",
    "    summary.append((seq, n_frames, bpp, psnr))\n",
    "    print(f\"→ {bpp:.4f} bpp   |   {psnr:.2f} dB PSNR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800b5191-9a91-4fe2-b56d-d9e97824a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===========  SUMMARY  ===========\")\n",
    "print(f\"{'Sequence':20}  Frames   BPP     PSNR\")\n",
    "for seq, n, bpp, psnr in summary:\n",
    "    print(f\"{seq:20}  {n:6d}   {bpp:5.4f}   {psnr:6.2f}\")\n",
    "overall_bpp  = sum(bpp*n for (_,n,bpp,_) in summary) / sum(n for (_,n,_,_) in summary)\n",
    "overall_psnr = sum(psnr*n for (_,n,_,psnr) in summary) / sum(n for (_,n,_,_) in summary)\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"{'Overall':20}          {overall_bpp:5.4f}   {overall_psnr:6.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66936367-0b37-4d70-81b4-0e30fc55b07e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-compressai]",
   "language": "python",
   "name": "conda-env-.mlspace-compressai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
